{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chicago, IL : Car Crash Analysis & Predictive Modeling\n",
    "\n",
    "\n",
    "### *Predicting car crashes with Machine Learning Models*\n",
    "\n",
    "Authors: [Christos Maglaras](mailto:Christo111M@gmail.com), [Marcos Panyagua](mailto:marcosvppfernandes@gmail.com), [Jamie Dowat](mailto:jamie_dowat44@yahoo.com)\n",
    "\n",
    "![chicago](img/chicago_night_drive.jpg)\n",
    "\n",
    "\n",
    "\n",
    "### Stakeholder: Chicago Department of Transportation\n",
    "\n",
    "![cdot](img/cdot.png)\n",
    "\n",
    "### Business Problem\n",
    "A report from the National Safety Council estimates that even with a decrease of 13% of miles driven last year, 42,060 people died in a vehicle crash in 2020. That is a 8% increase compared to the same period in 2019.\n",
    "A report from the National Safety Council estimates that even with a decrease of 13% of miles driven last year, 42,060 people died in a vehicle crash in 2020. That is a 8% increase compared to the same period in 2019.\n",
    "For the Chicago Tribune, one of the media vehicles that the report was published, Ken Kolosh, the safety council’s manager of statistics said that “The pandemic appears to be taking our eyes off the ball when it comes to traffic safety”.\n",
    "Michael Hanson, director of the Minnesota Public Safety Department’s Office of Traffic Safety, ratify the same: “We’re seeing a huge increase in the amount of risk-taking behavior”.\n",
    "So we decided to take data from the City of Chicago portal and make a deeper analisis on the three datasets they have avaible and see if we can somehow pinpoint some of the causes and suggest implementations to improve the safety of the city.\n",
    "\n",
    "\n",
    "## Project Requirements:\n",
    "\n",
    "Problem First: Start with a problem that you are interested in that you could potentially solve with a classification model. Then look for data that you could use to solve that problem. This approach is high-risk, high-reward: Very rewarding if you are able to solve a problem you are invested in, but frustrating if you end up sinking lots of time in without finding appropriate data. To mitigate the risk, set a firm limit for the amount of time you will allow yourself to look for data before moving on to the Data First approach.\n",
    "\n",
    "Data First: Take a look at some of the most popular internet repositories of cool data sets we've listed below. If you find a data set that's particularly interesting for you, then it's totally okay to build your problem around that data set.\n",
    "\n",
    "### Car Crash data:\n",
    "\n",
    "Build a classifier to predict the primary contributory cause of a car accident, given information about the car, the people in the car, the road conditions etc. You might imagine your audience as a Vehicle Safety Board who's interested in reducing traffic accidents, or as the City of Chicago who's interested in becoming aware of any interesting patterns. Note that there is a multi-class classification problem. You will almost certainly want to bin or trim or otherwise limit the number of target categories on which you ultimately predict. Note e.g. that some primary contributory causes have very few samples.\n",
    "\n",
    "# EDA\n",
    "Crash data shows information about each traffic crash on city streets within the **City of Chicago** limits and under the jurisdiction of Chicago Police Department (CPD). Data are shown as is from the electronic crash reporting system (E-Crash) at CPD, excluding any personally identifiable information. Records are added to the data portal when a crash report is finalized or when amendments are made to an existing report in E-Crash. Data from E-Crash are available for some police districts in 2015, but citywide data are not available until September 2017. About half of all crash reports, mostly minor crashes, are self-reported at the police district by the driver(s) involved and the other half are recorded at the scene by the police officer responding to the crash. Many of the crash parameters, including street condition data, weather condition, and posted speed limits, are recorded by the reporting officer based on best available information at the time, but many of these may disagree with posted information or other assessments on road conditions. If any new or updated information on a crash is received, the reporting officer may amend the crash report at a later time. A traffic crash within the city limits for which CPD is not the responding police agency, typically crashes on interstate highways, freeway ramps, and on local roads along the City boundary, are excluded from this dataset.\n",
    "\n",
    "All crashes are recorded as per the format specified in the Traffic Crash Report, SR1050, of the Illinois Department of Transportation. **As per Illinois statute, only crashes with a property damage value of *1,500 or more* or involving bodily injury to any person(s) and that happen on a public roadway and that involve at least one moving vehicle, except bike dooring, are considered reportable crashes.** However, CPD records every reported traffic crash event, regardless of the statute of limitations, and hence any formal Chicago crash dataset released by Illinois Department of Transportation may not include all the crashes listed here.\n",
    "\n",
    "## Data: [Chicago City Data Portal](https://data.cityofchicago.org/)\n",
    "\n",
    "![ccdp](img/chicagocitydataportal.jpg)\n",
    "\n",
    "### [Crashes](https://data.cityofchicago.org/Transportation/Traffic-Crashes-Crashes/85ca-t3if):\n",
    "\n",
    "##### Number of Rows: 482,866\n",
    "\n",
    "*Shows crash data from crash from the Chicago Police Department's **E-Crash** system*\n",
    "\n",
    "**\"All crashes are recorded as per the format specified in the Traffic Crash Report, SR1050, of the Illinois Department of Transportation.\"**\n",
    "\n",
    "| Column Name                 | Description                |\n",
    "| --------------------------- | -------------------------- |\n",
    "| crash_record_id  |  Can be used to link to the same crash in the Vehicles and People datasets. |\n",
    "| rd_no | Chicago Police Department report number|\n",
    "| crash_date | Date and time of crash as entered by the reporting officer |\n",
    "| posted_speed_limit  | Posted speed limit, as determined by reporting officer |\n",
    "| traffic_control_device | Traffic control device present at crash location, as determined by reporting officer (signals, stop sign, etc) |\n",
    "| device_condition  | Condition of traffic control device, as determined by reporting officer |\n",
    "| weather_condition | Weather condition at time of crash, as determined by reporting officer |\n",
    "| lighting_condition | Light condition at time of crash, as determined by reporting officer |\n",
    "| first_crash_type | Type of first collision in crash |\n",
    "| trafficway_type  | Trafficway type, as determined by reporting officer |\n",
    "| lane_ct | Total number of through lanes in either direction, excluding turn lanes, as determined by reporting officer (0 = intersection)|\n",
    "| alignment | Street alignment at crash location, as determined by reporting officer |\n",
    "| roadway_surface_cond        | Road surface condition, as determined by reporting officer |\n",
    "| road_defect | Road defects, as determined by reporting officer |\n",
    "| crash_type | A general severity classification for the crash. Can be either Injury and/or Tow Due to Crash or No Injury / Drive Away |\n",
    "| damage | A field observation of estimated damage. |\n",
    "| prim_contributory_cause   | The factor which was most significant in causing the crash, as determined by officer judgment |\n",
    "| sec_contributory_cause | The factor which was second most significant in causing the crash, as determined by officer judgment |\n",
    "| street_name | Street address name of crash location, as determined by reporting officer|\n",
    "| num_units | Number of units involved in the crash. A unit can be a motor vehicle, a pedestrian, a bicyclist, or another non-passenger roadway user. Each unit represents a mode of traffic with an independent trajectory. |\n",
    "| most_severe_injury | Most severe injury sustained by any person involved in the crash |\n",
    "| injuries_total | Total persons sustaining fatal, incapacitating, non-incapacitating, and possible injuries as determined by the reporting officer |\n",
    "| injuries_fatal | Total persons sustaining fatal injuries in the crash |\n",
    "| injuries_incapacitating | Total persons sustaining incapacitating/serious injuries in the crash as determined by the reporting officer. Any injury other than fatal injury, which prevents the injured person from walking, driving, or normally continuing the activities they were capable of performing before the injury occurred. Includes severe lacerations, broken limbs, skull or chest injuries, and abdominal injuries. |\n",
    "| injuries_non_incapacitating | Total persons sustaining non-incapacitating injuries in the crash as determined by the reporting officer. Any injury, other than fatal or incapacitating injury, which is evident to observers at the scene of the crash. Includes lump on head, abrasions, bruises, and minor lacerations. |\n",
    "| crash_hour | The hour of the day component of CRASH_DATE. |\n",
    "| crash_day_of_week | The day of the week component of CRASH_DATE. Sunday=1 |\n",
    "| latitude | The latitude of the crash location, as determined by reporting officer, as derived from the reported address of crash |\n",
    "| longitude | The longitude of the crash location, as determined by reporting officer, as derived from the reported address of crash |\n",
    "\n",
    "\n",
    "### [People](https://data.cityofchicago.org/Transportation/Traffic-Crashes-People/u6pd-qa9d):\n",
    "\n",
    "##### Number of Rows: 1,068,637\n",
    "\n",
    "*Information about people involved in a crash and if any injuries were sustained.*\n",
    "\n",
    "| Column Name                 | Description                |\n",
    "| --------------------------- | -------------------------- |\n",
    "| crash_record_id | This number can be used to link to the same crash in the Crashes and Vehicles datasets. This number also serves as a unique ID in the Crashes dataset. |\n",
    "| person_type | Type of roadway user involved in crash |\n",
    "| rd_no | Chicago Police Department report number. For privacy reasons, this column is blank for recent crashes. |\n",
    "| crash_date | Date and time of crash as entered by the reporting officer |\n",
    "| seat_no | Code for seating position of motor vehicle occupant: 1= driver, 2= center front, 3 = front passenger, 4 = second row left, 5 = second row center, 6 = second row right, 7 = enclosed passengers, 8 = exposed passengers, 9= unknown position, 10 = third row left, 11 = third row center, 12 = third row right |\n",
    "| city | City of residence of person involved in crash |\n",
    "| state | State of residence of person involved in crash |\n",
    "| zipcode | ZIP Code of residence of person involved in crash |\n",
    "| sex | Gender of person involved in crash, as determined by reporting officer |\n",
    "| age | Age of person involved in crash |\n",
    "| drivers_license_state | State issuing driver's license of person involved in crash |\n",
    "| drivers_license_class | Class of driver's license of person involved in crash |\n",
    "| safety_equipment | Safety equipment used by vehicle occupant in crash, if any |\n",
    "| airbag_deployed | Whether vehicle occupant airbag deployed as result of crash |\n",
    "| ejection | Whether vehicle occupant was ejected or extricated from the vehicle as a result of crash |\n",
    "| injury_classification | Severity of injury person sustained in the crash |\n",
    "| driver_action | Driver action that contributed to the crash, as determined by reporting officer |\n",
    "| driver_vision | What, if any, objects obscured the driver’s vision at time of crash |\n",
    "| physical_condition | Driver’s apparent physical condition at time of crash, as observed by the reporting officer |\n",
    "| pedpedal_action | Action of pedestrian or cyclist at the time of crash |\n",
    "| pedpedal_visibility | Visibility of pedestrian of cyclist safety equipment in use at time of crash |\n",
    "| pedpedal_location | Location of pedestrian or cyclist at the time of crash |\n",
    "| bac_result | Status of blood alcohol concentration testing for driver or other person involved in crash |\n",
    "| bac_result value | Driver’s blood alcohol concentration test result (fatal crashes may include pedestrian or cyclist results) |\n",
    "| cell_phone_use | Whether person was/was not using cellphone at the time of the crash, as determined by the reporting officer |\n",
    "\n",
    "### [Vehicles](https://data.cityofchicago.org/Transportation/Traffic-Crashes-Vehicles/68nd-jvt3):\n",
    "\n",
    "##### Number of Rows: 987,148\n",
    "\n",
    "*Information about vehicles (\"units\") involved in a traffic crash.*\n",
    "\n",
    "| Column Name                 | Description                |\n",
    "| --------------------------- | -------------------------- |\n",
    "| crash_record_id | This number can be used to link to the same crash in the Crashes and People datasets. This number also serves as a unique ID in the Crashes dataset. |\n",
    "| rd_no | Chicago Police Department report number. For privacy reasons, this column is blank for recent crashes. |\n",
    "| crash_date | Date and time of crash as entered by the reporting officer |\n",
    "| unit_type | The type of unit (i.e Driver, parked, pedestrian, bicycle, etc) |\n",
    "| num_passengers | Number of passengers in the vehicle. The driver is not included. More information on passengers is in the People dataset. |\n",
    "| make | The make (brand) of the vehicle, if relevant |\n",
    "| model | The model of the vehicle, if relevant |\n",
    "| lic_plate_state | The state issuing the license plate of the vehicle, if relevant |\n",
    "| vehicle_year | The model year of the vehicle, if relevant |\n",
    "| vehicle_defect | Indicates part of car containing defect (brakes, wheels, etc.) |\n",
    "| vehicle_type | The type of vehicle, if relevant (passenger, truck, bus, etc) |\n",
    "| vehicle_use | The normal use of the vehicle, if relevant |\n",
    "| maneuver | The action the unit was taking prior to the crash, as determined by the reporting officer |\n",
    "| towed_I | Indicator of whether the vehicle was towed |\n",
    "| occupant_cnt | The number of people in the unit, as determined by the reporting officer |\n",
    "| exceed_speed_limit_I | Indicator of whether the unit was speeding, as determined by the reporting officer |\n",
    "| first_contact_point | Indicates orientation on car that was hit (front, rear, etc) |\n",
    "\n",
    "## Repository Structure\n",
    "\n",
    "├── data <br>\n",
    "....├── traffic_crashes_chicago.csv<br>\n",
    "....├── traffic_crashes_people.csv<br>\n",
    "....└── traffic_crashes_vehicles.csv<br>\n",
    "├── img<br>\n",
    "....├── cdot.png<br>\n",
    "....├── chicago_night_drive.jpg<br>\n",
    "....├── chicagocitydataportal.jpg<br>\n",
    "....├── finalmodeleltestcm.png<br>\n",
    "....├── finalmodeltraincm.png<br>\n",
    "....├── scoringsafety.png<br>\n",
    "....└── visionzeroquotes.png<br>\n",
    "├── notebooks<br>\n",
    "....├── Christos_notebook.ipynb<br>\n",
    "....├── jamie_notebook.ipynb<br>\n",
    "....└── marcos_eda.ipynb<br>\n",
    "├── src<br>\n",
    "....├── __init__.py<br>\n",
    "....├── data_cleaning.py<br>\n",
    "....├── eda.py<br>\n",
    "....└── models.py<br>\n",
    "├──presentation.pdf<br>\n",
    "├── final_notebook.ipynb<br>\n",
    "└── README.md<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'traffic_crashes_chicago.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-3fa40e568e13>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Source: https://data.cityofchicago.org/Transportation/Traffic-Crashes-Crashes/85ca-t3if\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'traffic_crashes_chicago.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1176\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1179\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2008\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'traffic_crashes_chicago.csv'"
     ]
    }
   ],
   "source": [
    "# Source: https://data.cityofchicago.org/Transportation/Traffic-Crashes-Crashes/85ca-t3if \n",
    "data = pd.read_csv('traffic_crashes_chicago.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_info(data):\n",
    "    print(\"Dataset shape is: \", data.shape)\n",
    "    print(\"Dataset size is: \", data.size)\n",
    "    print(\"Dataset columns are: \", data.columns)\n",
    "    print(\"Dataset info is: \", data.info())\n",
    "    categorical = []\n",
    "    numerical = []\n",
    "    for i in data.columns:\n",
    "        if data[i].dtype == object:\n",
    "            categorical.append(i)\n",
    "        else:\n",
    "            numerical.append(i)\n",
    "    print(\"Categorical variables are:\\n \", categorical)\n",
    "    print(\"Numerical variables are:\\n \", numerical)\n",
    "    return categorical, numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.LATITUDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.CRASH_DATE_EST_I.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fsm = data.fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_fsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lots_o_missing = ['CRASH_RECORD_ID', 'dead?']\n",
    "for col in data_fsm.columns:\n",
    "    if len(data_fsm[col][data_fsm[col]==0]) > 300000:\n",
    "        lots_o_missing.append(col)\n",
    "lots_o_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['HIT_AND_RUN_I'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fsm['dead?'] = np.where(data_fsm['INJURIES_FATAL']>0, 1, 0)\n",
    "data_fsm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "X = data_fsm.drop(labels=lots_o_missing, axis=1).select_dtypes(exclude='object')\n",
    "y = data_fsm['dead?']\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, plot_tree \n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X, y)\n",
    "dt.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fsm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "plot_confusion_matrix(dt, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "X_resampled, y_resampled = smote.fit_sample(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = [data.columns[i].lower() for i in range(len(data.columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[111].crash_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['month'] = data['crash_date'].apply(lambda x: int(x[:2]))\n",
    "data['day'] = data['crash_date'].apply(lambda x: int(x[3:5]))\n",
    "data['year'] = data['crash_date'].apply(lambda x: int(x[6:10]))\n",
    "data['time_of_crash'] = data['crash_date'].apply(\n",
    "    lambda x: int(x[11:13]+x[14:16]+x[17:19]) if 'AM' in x else int((str(int(x[11:13])+12))+x[14:16]+x[17:19])\n",
    ")\n",
    "data['time_of_crash'].iloc[111]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.crash_date.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install folium\n",
    "import folium\n",
    "from folium import plugins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chimap = folium.Map(location=[41.878876, -87.635918],\n",
    "                    zoom_start = 12,\n",
    "                    control_scale=True,\n",
    "                   tiles = \"OpenStreetMap\")\n",
    "\n",
    "folium.raster_layers.TileLayer('Open Street Map').add_to(chimap)\n",
    "folium.raster_layers.TileLayer('Stamen Toner').add_to(chimap)\n",
    "folium.raster_layers.TileLayer('Stamen Watercolor').add_to(chimap)\n",
    "folium.raster_layers.TileLayer('CartoDB Positron').add_to(chimap)\n",
    "folium.raster_layers.TileLayer('CartoDB Dark_Matter').add_to(chimap)\n",
    "folium.raster_layers.TileLayer('Stamen Terrain').add_to(chimap)\n",
    "\n",
    "\n",
    "# folium.LayerControl().add_to(chimap)\n",
    "\n",
    "minimap = plugins.MiniMap(toggle_display=True)\n",
    "chimap.add_child(minimap)\n",
    "\n",
    "plugins.Fullscreen(position='topright').add_to(chimap)\n",
    "\n",
    "draw = plugins.Draw(export=True)\n",
    "draw.add_to(chimap)\n",
    "display(chimap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipmap = folium.Map(location=[41.878876, -87.635918],\n",
    "                     zoom_start = 10)\n",
    "zipcodes = \"https://data.cityofchicago.org/api/geospatial/gdcf-axmw?method=export&format=GeoJSON\"\n",
    "folium.GeoJson(zipcodes, name=\"Chicago Zipcodes\").add_to(zipmap)\n",
    "dataheat['LIGHTING_CONDITION'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start of lighting_condition mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataheat = data.dropna(subset = ['LATITUDE'])\n",
    "\n",
    "dataheatdaylight = dataheat[dataheat['LIGHTING_CONDITION'] == 'DAYLIGHT']\n",
    "dataheatdarknesslight = dataheat[dataheat['LIGHTING_CONDITION'] == 'DARKNESS, LIGHTED ROAD']\n",
    "dataheatdarkness = dataheat[dataheat['LIGHTING_CONDITION'] == 'DARKNESS']\n",
    "dataheatunknown = dataheat[dataheat['LIGHTING_CONDITION'] == 'UNKNOWN']\n",
    "dataheatdusk = dataheat[dataheat['LIGHTING_CONDITION'] == 'DUSK']\n",
    "dataheatdawn = dataheat[dataheat['LIGHTING_CONDITION'] == 'DAWN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folium.plugins.HeatMap(list(zip(dataheat['LATITUDE'], dataheat['LONGITUDE'])), radius=2, blur=3).add_to(chimap)\n",
    "folium.LayerControl().add_to(chimap)\n",
    "display(chimap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chimapdaylight = folium.Map(location=[41.878876, -87.635918],\n",
    "                    zoom_start = 12,\n",
    "                    control_scale=True,\n",
    "                   tiles = \"OpenStreetMap\")\n",
    "\n",
    "folium.plugins.HeatMap(list(zip(dataheatdaylight['LATITUDE'], dataheatdaylight['LONGITUDE'])), radius=2, blur=3).add_to(chimapdaylight)\n",
    "folium.LayerControl().add_to(chimapdaylight)\n",
    "plugins.Fullscreen(position='topright').add_to(chimapdaylight)\n",
    "\n",
    "display(chimapdaylight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chimapdarknesslight = folium.Map(location=[41.878876, -87.635918],\n",
    "                    zoom_start = 12,\n",
    "                    control_scale=True,\n",
    "                   tiles = \"OpenStreetMap\")\n",
    "\n",
    "folium.plugins.HeatMap(list(zip(dataheatdarknesslight['LATITUDE'], dataheatdarknesslight['LONGITUDE'])), radius=2, blur=3).add_to(chimapdarknesslight)\n",
    "folium.LayerControl().add_to(chimapdarknesslight)\n",
    "plugins.Fullscreen(position='topright').add_to(chimapdarknesslight)\n",
    "\n",
    "display(chimapdarknesslight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chimapdarkness = folium.Map(location=[41.878876, -87.635918],\n",
    "                    zoom_start = 12,\n",
    "                    control_scale=True,\n",
    "                   tiles = \"OpenStreetMap\")\n",
    "\n",
    "folium.plugins.HeatMap(list(zip(dataheatdarkness['LATITUDE'], dataheatdarkness['LONGITUDE'])), radius=2, blur=3).add_to(chimapdarkness)\n",
    "folium.LayerControl().add_to(chimapdarkness)\n",
    "plugins.Fullscreen(position='topright').add_to(chimapdarkness)\n",
    "\n",
    "display(chimapdarkness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chimapunknown = folium.Map(location=[41.878876, -87.635918],\n",
    "                    zoom_start = 12,\n",
    "                    control_scale=True,\n",
    "                   tiles = \"OpenStreetMap\")\n",
    "\n",
    "folium.plugins.HeatMap(list(zip(dataheatunknown['LATITUDE'], dataheatunknown['LONGITUDE'])), radius=2, blur=3).add_to(chimapunknown)\n",
    "folium.LayerControl().add_to(chimapunknown)\n",
    "plugins.Fullscreen(position='topright').add_to(chimapunknown)\n",
    "\n",
    "display(chimapunknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chimapdusk = folium.Map(location=[41.878876, -87.635918],\n",
    "                    zoom_start = 12,\n",
    "                    control_scale=True,\n",
    "                   tiles = \"OpenStreetMap\")\n",
    "\n",
    "folium.plugins.HeatMap(list(zip(dataheatdusk['LATITUDE'], dataheatdusk['LONGITUDE'])), radius=2, blur=3).add_to(chimapdusk)\n",
    "folium.LayerControl().add_to(chimapdusk)\n",
    "plugins.Fullscreen(position='topright').add_to(chimapdusk)\n",
    "\n",
    "display(chimapdusk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chimapdawn = folium.Map(location=[41.878876, -87.635918],\n",
    "                    zoom_start = 12,\n",
    "                    control_scale=True,\n",
    "                   tiles = \"OpenStreetMap\")\n",
    "\n",
    "folium.plugins.HeatMap(list(zip(dataheatdawn['LATITUDE'], dataheatdawn['LONGITUDE'])), radius=2, blur=3).add_to(chimapdawn)\n",
    "folium.LayerControl().add_to(chimapdawn)\n",
    "plugins.Fullscreen(position='topright').add_to(chimapdawn)\n",
    "\n",
    "display(chimapdawn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of lighting_condition mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inj_acc = data[data['INJURIES_TOTAL'] > 0]\n",
    "fat_acc = inj_acc[inj_acc['INJURIES_FATAL'] > 0]\n",
    "print(f'{(len(fat_acc)/len(inj_acc))*100} percent of injurious accidents result in deaths')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start of injuries_total mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datainj = data[data['INJURIES_TOTAL'] > 0]\n",
    "datainjuries = datainj.dropna(subset = ['LATITUDE'])\n",
    "datainjuries['LATITUDE'].isna().sum()\n",
    "\n",
    "\n",
    "chiinjuries = folium.Map(location=[41.878876, -87.635918],\n",
    "                    zoom_start = 12,\n",
    "                    control_scale=True,\n",
    "                   tiles = \"OpenStreetMap\")\n",
    "\n",
    "folium.plugins.HeatMap(list(zip(datainjuries['LATITUDE'], datainjuries['LONGITUDE'])), radius=2, blur=3).add_to(chiinjuries)\n",
    "folium.LayerControl().add_to(chiinjuries)\n",
    "plugins.Fullscreen(position='topright').add_to(chiinjuries)\n",
    "\n",
    "display(chiinjuries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datainjy = data[data['INJURIES_TOTAL'] == 0]\n",
    "datainjuriesy = datainjy.dropna(subset = ['LATITUDE'])\n",
    "datainjuriesy['LATITUDE'].isna().sum()\n",
    "\n",
    "\n",
    "chiinjuriesy = folium.Map(location=[41.878876, -87.635918],\n",
    "                    zoom_start = 12,\n",
    "                    control_scale=True,\n",
    "                   tiles = \"OpenStreetMap\")\n",
    "\n",
    "folium.plugins.HeatMap(list(zip(datainjuriesy['LATITUDE'], datainjuriesy['LONGITUDE'])), radius=2, blur=3).add_to(chiinjuriesy)\n",
    "folium.LayerControl().add_to(chiinjuriesy)\n",
    "plugins.Fullscreen(position='topright').add_to(chiinjuriesy)\n",
    "\n",
    "display(chiinjuriesy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of injuries_total mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start of weekday graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_no_inj = data[data['INJURIES_TOTAL'] == 0]\n",
    "crash_inj    = data[data['INJURIES_TOTAL'] > 0]\n",
    "\n",
    "crash_no_inj = crash_no_inj.groupby('CRASH_DAY_OF_WEEK').sum()\n",
    "crash_inj    = crash_inj.groupby('CRASH_DAY_OF_WEEK').sum()\n",
    "\n",
    "cni = crash_no_inj['NUM_UNITS']\n",
    "cyi = crash_inj['NUM_UNITS']\n",
    "\n",
    "cni = pd.DataFrame(cni)\n",
    "cyi = pd.DataFrame(cyi)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "sns.set_color_codes(\"muted\")\n",
    "sns.barplot(x=cni.index, y=\"NUM_UNITS\", data=cni,\n",
    "            label=\"No Injury Accidents\", color=\"m\")\n",
    "\n",
    "sns.set_color_codes(\"muted\")\n",
    "sns.barplot(x=cyi.index, y=\"NUM_UNITS\", data=cyi,\n",
    "            label=\"Injury Accidents\", color=\"r\")\n",
    "\n",
    "ax.legend(ncol=2, loc=\"lower right\", frameon=True)\n",
    "ax.set(ylabel=\"Crashes\", xlabel=\"Day of Week\")\n",
    "sns.despine(left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of weekday graphing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start of month graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_no_inj = data[data['INJURIES_TOTAL'] == 0]\n",
    "crash_inj    = data[data['INJURIES_TOTAL'] > 0]\n",
    "\n",
    "crash_no_inj = crash_no_inj.groupby('CRASH_MONTH').sum()\n",
    "crash_inj    = crash_inj.groupby('CRASH_MONTH').sum()\n",
    "\n",
    "cni = crash_no_inj['NUM_UNITS']\n",
    "cyi = crash_inj['NUM_UNITS']\n",
    "\n",
    "cni = pd.DataFrame(cni)\n",
    "cyi = pd.DataFrame(cyi)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "sns.set_color_codes(\"muted\")\n",
    "sns.barplot(x=cni.index, y=\"NUM_UNITS\", data=cni,\n",
    "            label=\"No Injury Accidents\", color=\"m\")\n",
    "\n",
    "sns.set_color_codes(\"muted\")\n",
    "sns.barplot(x=cyi.index, y=\"NUM_UNITS\", data=cyi,\n",
    "            label=\"Injury Accidents\", color=\"r\")\n",
    "\n",
    "ax.legend(ncol=2, loc=\"lower right\", frameon=True)\n",
    "ax.set(ylabel=\"Crashes\", xlabel=\"Month\")\n",
    "sns.despine(left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of month graphing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start hourly graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_no_inj = data[data['INJURIES_TOTAL'] == 0]\n",
    "crash_inj    = data[data['INJURIES_TOTAL'] > 0]\n",
    "\n",
    "crash_no_inj = crash_no_inj.groupby('CRASH_HOUR').sum()\n",
    "crash_inj    = crash_inj.groupby('CRASH_HOUR').sum()\n",
    "\n",
    "cni = crash_no_inj['NUM_UNITS']\n",
    "cyi = crash_inj['NUM_UNITS']\n",
    "\n",
    "cni = pd.DataFrame(cni)\n",
    "cyi = pd.DataFrame(cyi)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "sns.set_color_codes(\"muted\")\n",
    "sns.barplot(x=cni.index, y=\"NUM_UNITS\", data=cni,\n",
    "            label=\"No Injury Accidents\", color=\"m\")\n",
    "\n",
    "sns.set_color_codes(\"muted\")\n",
    "sns.barplot(x=cyi.index, y=\"NUM_UNITS\", data=cyi,\n",
    "            label=\"Injury Accidents\", color=\"r\")\n",
    "\n",
    "ax.legend(ncol=2, loc=\"lower right\", frameon=True)\n",
    "ax.set(ylabel=\"Crashes\", xlabel=\"Hour\")\n",
    "sns.despine(left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End hourly graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('traffic_crashes_chicago.csv')\n",
    "\n",
    "df\n",
    "# = df.drop(['CRASH_RECORD_ID', 'RD_NO', 'CRASH_DATE_EST_I', 'CRASH_DATE', 'TRAFFIC_CONTROL_DEVICE',\n",
    "              'DEVICE_CONDITION', 'FIRST_CRASH_TYPE', 'TRAFFICWAY_TYPE', 'ALIGNMENT', 'REPORT_TYPE',\n",
    "              'CRASH_TYPE', 'INTERSECTION_RELATED_I', 'NOT_RIGHT_OF_WAY_I', 'HIT_AND_RUN_I', 'DAMAGE',\n",
    "              'DATE_POLICE_NOTIFIED', 'PRIM_CONTRIBUTORY_CAUSE', 'SEC_CONTRIBUTORY_CAUSE', 'STREET_NAME',\n",
    "              'BEAT_OF_OCCURRENCE', 'PHOTOS_TAKEN_I', 'STATEMENTS_TAKEN_I', 'DOORING_I', 'WORK_ZONE_I',\n",
    "              'WORK_ZONE_TYPE', 'WORKERS_PRESENT_I', 'MOST_SEVERE_INJURY', 'STREET_NO', 'INJURIES_FATAL',\n",
    "              'INJURIES_INCAPACITATING', 'INJURIES_NON_INCAPACITATING', 'INJURIES_REPORTED_NOT_EVIDENT',\n",
    "              'INJURIES_NO_INDICATION', 'INJURIES_UNKNOWN', 'LATITUDE', 'LONGITUDE',  'LOCATION', 'LANE_CNT'], axis=1)\n",
    "df['STREET_DIRECTION'].fillna(method='ffill', inplace=True)\n",
    "df['target-injuries'] = df['INJURIES_TOTAL'] > 0\n",
    "df.drop('INJURIES_TOTAL', axis=1, inplace=True)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "df['WEATHER_CONDITION'] = lbl.fit_transform(df['WEATHER_CONDITION'].astype(str))\n",
    "df['LIGHTING_CONDITION'] = lbl.fit_transform(df['LIGHTING_CONDITION'].astype(str))\n",
    "df['ROADWAY_SURFACE_COND'] = lbl.fit_transform(df['ROADWAY_SURFACE_COND'].astype(str))\n",
    "df['ROAD_DEFECT'] = lbl.fit_transform(df['ROAD_DEFECT'].astype(str))\n",
    "df['STREET_DIRECTION'] = lbl.fit_transform(df['STREET_DIRECTION'].astype(str))\n",
    "\n",
    "X = df.drop('target-injuries', axis=1)\n",
    "y = df['target-injuries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2)\n",
    "D_train = xgb.DMatrix(X_train, label=Y_train)\n",
    "D_test  = xgb.DMatrix(X_test, label=Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#         'min_child_weight': [5,6,7,8],\n",
    "#         'gamma'           : [1.1,1.2,1.3],\n",
    "#         'subsample'       : [.7,.8,.9],\n",
    "#         'max_depth'       : [10,11,12,13],\n",
    "#         'eta'             : [.2,.3,.4],\n",
    "#         'colsample_bytree': [.4,.5,.6]        \n",
    "#         }\n",
    "# subsample': 0.8, 'max_depth': 10, 'gamma': 1, 'colsample_bytree': 0.6\n",
    "# subsample': 0.8, 'max_depth': 11, 'gamma': 1.1, 'eta': 0.3, 'colsample_bytree': 0.7\n",
    "# subsample': 0.8, 'min_child_weight': 6, 'max_depth': 11, 'gamma': 1.1, 'eta': 0.3, 'colsample_bytree': 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num = 1\n",
    "# for each in params.values():\n",
    "#     num = num * len(each)\n",
    "#     print(f'Thre are {num*folds} combinations')\n",
    "# print(f'{(folds*param_comb*6*3)/60} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb = XGBClassifier(learning_rate=0.02,\n",
    "#                     n_estimators=600,\n",
    "#                     objective='binary:logistic',\n",
    "#                     silent=True,\n",
    "#                     nthread=1,\n",
    "#                     tree_method= 'gpu_hist'\n",
    "# #                     verbosity=0,\n",
    "# #                    scale_pos_weight = 7\n",
    "#                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folds = 5\n",
    "# param_comb = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n",
    "\n",
    "# random_search = RandomizedSearchCV(xgb,\n",
    "#                                    param_distributions=params,\n",
    "#                                    n_iter=param_comb,\n",
    "#                                    scoring='roc_auc',\n",
    "#                                    n_jobs=4,\n",
    "#                                    cv=skf.split(X_train,Y_train),\n",
    "#                                    verbose=3,\n",
    "#                                    random_state=1001 )\n",
    "\n",
    "# start_time = timer(None)\n",
    "# random_search.fit(X_train, Y_train)\n",
    "# timer(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\n All results:')\n",
    "# print(random_search.cv_results_)\n",
    "# print('\\n Best estimator:')\n",
    "# print(random_search.best_estimator_)\n",
    "# print('\\n Best normalized gini score for %d-fold search with %d parameter combinations:' % (folds, param_comb))\n",
    "# print(random_search.best_score_)\n",
    "# #       * 2 - 1)\n",
    "# print('\\n Best hyperparameters:')\n",
    "# print(random_search.best_params_)\n",
    "# results = pd.DataFrame(random_search.cv_results_)\n",
    "# results.to_csv('xgb-random-grid-search-results-01.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes parameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install bayesian-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y_train.astype('int')\n",
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "classifier1 = XGBClassifier().fit(X_train, Y_train)\n",
    "\n",
    "train_p1 = classifier1.predict(X_train)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, hamming_loss\n",
    "print(classification_report(Y_train, train_p1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(train_p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(train_p1, Y_train)\n",
    "acc = cm.diagonal().sum()/cm.sum()\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bo_tune_xgb(max_depth, gamma, n_estimators ,learning_rate, scale_pos_weight, min_child_weight, colsample_bytree):\n",
    "    params = {'max_depth'       : int(max_depth),\n",
    "              'gamma'           : gamma,\n",
    "              'n_estimators'    : int(n_estimators),\n",
    "              'learning_rate'   : learning_rate,\n",
    "              'subsample'       : 0.8,\n",
    "              'eval_metric'     : 'rmse',\n",
    "              'min_child_weight': min_child_weight,\n",
    "              'scale_pos_weight': scale_pos_weight,\n",
    "              'colsample_bytree': colsample_bytree,\n",
    "              'tree_method'     : 'gpu_hist'}\n",
    "    cv_result = xgb.cv(params, D_train, num_boost_round=200, nfold=5)\n",
    "    return -1.0 * cv_result['test-rmse-mean'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_bo = BayesianOptimization(bo_tune_xgb, {'max_depth' : (3, 15),\n",
    "                        'gamma' : (0, 2),\n",
    "                        'learning_rate'    : (0,1),\n",
    "                        'n_estimators'     : (100,400),\n",
    "                        'scale_pos_weight' : (5,10),\n",
    "                        'min_child_weight' : (1,10),\n",
    "                        'colsample_bytree' : (0,1)})\n",
    "xgb_bo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_bo.maximize(n_iter=10, init_points=12, acq='ei')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = xgb_bo.max['params']\n",
    "print(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['max_depth']= int(params['max_depth'])\n",
    "params['n_estimators']= int(params['n_estimators'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier2 = XGBClassifier(**params).fit(X_train, Y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_p2 = classifier2.predict(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(train_p2, Y_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(train_p2, Y_train)\n",
    "acc = cm.diagonal().sum()/cm.sum()\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(train_p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "cf = confusion_matrix(train_p2, Y_train)\n",
    "sns.heatmap(cf/np.sum(cf), annot=True, fmt='.2%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "cf = confusion_matrix(train_p2, Y_train)\n",
    "sns.heatmap(cf/np.sum(cf), annot=True, fmt='.2%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
